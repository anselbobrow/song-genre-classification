{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from porter_stemmer import PorterStemmer\n",
    "import re, os\n",
    "from itertools import islice\n",
    "\n",
    "train_feature_file = './out/train.data'\n",
    "test_feature_file = './out/test.data'\n",
    "stop_words = set([x.strip() for x in open(\"stopwords.english\", encoding=\"ISO-8859-1\").readlines()])\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window(seq, n=2):\n",
    "    \"Returns a sliding window (of width n) over data from the iterable\"\n",
    "    \"   s -> (s0,s1,...s[n-1]), (s1,s2,...,sn), ...                   \"\n",
    "    it = iter(seq)\n",
    "    result = tuple(islice(it, n))\n",
    "    if len(result) == n:\n",
    "        yield result    \n",
    "    for elem in it:\n",
    "        result = result[1:] + (elem,)\n",
    "        yield result\n",
    "\n",
    "# from previous assignments\n",
    "def protect_meta_characters (text):\n",
    "    return text.replace(\",\", \"COMMA\").replace(\"=\",\"EQUALS\")\n",
    "\n",
    "def makefeat(attribute, value):\n",
    "    return attribute+\"=\"+protect_meta_characters(value)\n",
    "\n",
    "# custom lyrics tokenization for Genius formatting\n",
    "def tokenize(lyrics):\n",
    "    tokens = []\n",
    "    # return tokenized lyrics\n",
    "    lines = lyrics.splitlines()\n",
    "    for line in lines:\n",
    "        if line:\n",
    "            # ignore verse and intro markers etc\n",
    "            if line[0] == '[' and line[-1] == ']':\n",
    "                continue\n",
    "            words = [w.lower() for w in re.split(r\"\\s|([;\\-:.,?!'])\", line) if w]\n",
    "            tokens.extend([protect_meta_characters(stemmer.stem_token(w)) for w in words if w and w not in stop_words])\n",
    "    return tokens\n",
    "\n",
    "# takes a song with lyrics and genre and creates a feature set\n",
    "def generate_features(lyrics, genre, train=False):\n",
    "    features = []\n",
    "    tokens = tokenize(lyrics)\n",
    "\n",
    "    # unigrams\n",
    "    features.extend([makefeat('word', token) for token in tokens])\n",
    "\n",
    "    bigrams = window(tokens, 2)\n",
    "    trigrams = window(tokens, 3)\n",
    "\n",
    "    for bigram in bigrams:\n",
    "        features.append(makefeat('bigram', bigram[0]+ '+' + bigram[1]))\n",
    "\n",
    "    for trigram in trigrams:\n",
    "        features.append(makefeat('trigram', trigram[0]+'+'+trigram[1]+'+'+trigram[2]))\n",
    "\n",
    "    apostrophe_count = 0\n",
    "    comma_count = 0\n",
    "    period_count = 0\n",
    "    exclamation_count = 0\n",
    "    question_count = 0\n",
    "    semicolon_count = 0\n",
    "    colon_count = 0\n",
    "    hyphen_count = 0\n",
    "    digit_count = 0\n",
    "    Xx_count = 0\n",
    "    XX_count = 0\n",
    "\n",
    "    line_lengths = []\n",
    "    unique_line_lengths = []\n",
    "\n",
    "    word_lengths = []\n",
    "\n",
    "    for line in lyrics.split('\\n'):\n",
    "\n",
    "        line_lengths.append(len(line.split()))\n",
    "\n",
    "        unique_words = []\n",
    "        w = line.split()\n",
    "        if w not in unique_words:\n",
    "            unique_words.append(w)\n",
    "        unique_line_lengths.append(len(unique_words))\n",
    "\n",
    "        for word in line:\n",
    "            if word[0].isupper():\n",
    "                if word.isupper():\n",
    "                    XX_count += 1\n",
    "                else:\n",
    "                    Xx_count += 1\n",
    "            word_lengths.append(len(word))\n",
    "\n",
    "    avg_line_length = sum(line_lengths) / len(line_lengths)\n",
    "    unique_avg_line_length = sum(unique_line_lengths) / len(unique_line_lengths)\n",
    "    avg_word_length = sum(word_lengths) / len(word_lengths)\n",
    "\n",
    "    for token in tokens:\n",
    "        if token == \"'\":\n",
    "            apostrophe_count += 1\n",
    "        if token == \",\":\n",
    "            comma_count += 1\n",
    "        if token == \".\":\n",
    "            period_count += 1\n",
    "        if token == \"!\":\n",
    "            exclamation_count += 1\n",
    "        if token == \"?\":\n",
    "            question_count += 1\n",
    "        if token == \":\":\n",
    "            colon_count += 1\n",
    "        if token == \";\":\n",
    "            semicolon_count += 1\n",
    "        if token == \"-\":\n",
    "            hyphen_count += 1\n",
    "        if token.isdigit():\n",
    "            digit_count += 1\n",
    "\n",
    "\n",
    "    # add features for positive/negative words, positive and negative numbers, numbers of capitalized words\n",
    "    features.append(\"apostrophe=\"+str(apostrophe_count))\n",
    "    features.append(\"comma=\"+str(comma_count))\n",
    "    features.append(\"period=\"+str(period_count))\n",
    "    features.append(\"exclamation=\"+str(exclamation_count))\n",
    "    features.append(\"question=\"+str(question_count))\n",
    "    features.append(\"colon=\"+str(colon_count))\n",
    "    features.append(\"semicolon=\"+str(semicolon_count))\n",
    "    features.append(\"hyphen=\"+str(hyphen_count))\n",
    "\n",
    "    features.append(\"digit=\"+str(digit_count))\n",
    "\n",
    "    features.append(\"average_line_length=\"+str(avg_line_length))\n",
    "    features.append(\"unique_avg_line_length=\"+str(unique_avg_line_length))\n",
    "    features.append(\"avg_word_length=\"+str(avg_word_length))\n",
    "\n",
    "    features.append(\"Xx_count=\"+str(Xx_count))\n",
    "    features.append(\"XX_count=\"+str(XX_count))\n",
    "    \n",
    "    # add label\n",
    "    features.append(genre)\n",
    "\n",
    "    # write features to out file\n",
    "    with open(train_feature_file if train else test_feature_file, 'a') as f:\n",
    "        f.write(','.join(features) + '\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "hiphop_df = pd.read_pickle('./hiphop_df')\n",
    "pop_df = pd.read_pickle('./pop_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hiphop 0.969676480220604 pop 0.03032351977939594 \n",
      "hiphop 0.9831040774481231 pop 0.016895922551876854 \n",
      "hiphop 0.9871543173042845 pop 0.012845682695715519 \n",
      "hiphop 0.9826370636121425 pop 0.01736293638785739 \n",
      "hiphop 0.9602402919626045 pop 0.03975970803739551 \n",
      "hiphop 0.9936978419744826 pop 0.006302158025517395 \n",
      "hiphop 0.9339774195996259 pop 0.06602258040037408 \n",
      "hiphop 0.9992115504755636 pop 7.88449524436435E-4 \n",
      "hiphop 0.9694924383469355 pop 0.030507561653064435 \n",
      "hiphop 0.9567256777147257 pop 0.04327432228527427 \n",
      "hiphop 0.9590420569763336 pop 0.040957943023666295 \n",
      "hiphop 0.9525356907842621 pop 0.047464309215737875 \n",
      "hiphop 0.9029878389945927 pop 0.0970121610054073 \n",
      "hiphop 0.9849401805053035 pop 0.01505981949469641 \n",
      "hiphop 0.9910363315835014 pop 0.008963668416498722 \n",
      "pop 0.8670458373838247 hiphop 0.13295416261617524 \n",
      "hiphop 0.8423501597565765 pop 0.15764984024342346 \n",
      "hiphop 0.9098684537738706 pop 0.09013154622612946 \n",
      "hiphop 0.6298918685150072 pop 0.37010813148499283 \n",
      "pop 0.637843106413555 hiphop 0.36215689358644493 \n",
      "pop 0.9624758932588109 hiphop 0.03752410674118914 \n",
      "pop 0.9441270764543892 hiphop 0.055872923545610804 \n",
      "pop 0.7303036847409913 hiphop 0.26969631525900867 \n",
      "pop 0.8385663685917258 hiphop 0.16143363140827413 \n",
      "pop 0.9469835791896456 hiphop 0.05301642081035452 \n",
      "pop 0.7491921984710717 hiphop 0.2508078015289283 \n",
      "pop 0.5483407298022029 hiphop 0.4516592701977971 \n",
      "pop 0.6966793025444865 hiphop 0.30332069745551343 \n",
      "hiphop 0.7295483436064375 pop 0.2704516563935625 \n",
      "hiphop 0.8394455261373972 pop 0.16055447386260277 \n",
      "pop 0.639444514209029 hiphop 0.36055548579097096 \n",
      "pop 0.561158925961056 hiphop 0.438841074038944 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# erase old features\n",
    "open(train_feature_file, 'w').close()\n",
    "open(test_feature_file, 'w').close()\n",
    "\n",
    "ratio = 90\n",
    "\n",
    "# create features for training and test datasets\n",
    "hiphop_df.iloc[:ratio].apply(axis=1, func=lambda row: generate_features(row['lyrics'], 'hiphop', True))\n",
    "pop_df.iloc[:ratio].apply(axis=1, func=lambda row: generate_features(row['lyrics'], 'pop', True))\n",
    "\n",
    "hiphop_df.iloc[ratio:].apply(axis=1, func=lambda row: generate_features(row['lyrics'], 'hiphop'))\n",
    "pop_df.iloc[ratio:].apply(axis=1, func=lambda row: generate_features(row['lyrics'], 'pop'))\n",
    "\n",
    "# os.system(\"./naivebayes.py -t out/train.data -p out/test.data -l 2\")\n",
    "os.system(\"./bin/classify -sigma 1 train out/train.data out/model > /dev/null\")\n",
    "os.system(\"./bin/classify apply out/model out/test.data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ember', 'stai', 'breez', 'feel', 'element', 'remind', \"'\", 'beauti', \"'\", 'bleak', 'stuck', 'long', 'light', 'breath', '?', 'COMMA', 'love', 'COMMA', 'feel', 'time', 'jump', 'real', 'scar', 'heal', 'COMMA', 'won', \"'\", 'wave', 'won', \"'\", 'break', 'boat', 'wave', 'won', \"'\", 'brеak', 'boat', 'stone', 'crash', 'boardwalk', 'thе', 'wind', 'rush', 'tree', 'ey', 'peel', 'memori', 'fall', 'short', \"'\", 've', 'left', 'long', 'call', '?', 'COMMA', 'love', 'COMMA', 'feel', 'time', 'jump', 'real', 'scar', 'heal', 'COMMA', 'won', \"'\", 'wave', 'won', \"'\", 'break', 'boat', 'wave', 'won', \"'\", 'break', 'boat', 'wave', 'won', \"'\", 'break', 'boat', 'wave', 'won', \"'\", 'break', 'boat', 'love', 'COMMA', 'feel', 'time', 'jump', 'real', 'scar', 'heal', 'COMMA', 'won', \"'\", 'wave', 'won', \"'\", 'break', 'boat']\n"
     ]
    }
   ],
   "source": [
    "# evaluate songs \n",
    "print(tokenize(pop_df.iloc[0]['lyrics']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
